# Complete Data Flow Diagrams

## 1. User Request Flow - Mining Calculator

```mermaid
sequenceDiagram
    actor User as ğŸ‘¤ User
    participant Browser as ğŸŒ Browser
    participant Flask as âš™ï¸ Flask App
    participant Auth as ğŸ” Auth System
    participant Cache as âš¡ Redis Cache
    participant DB as ğŸ—„ï¸ PostgreSQL
    participant CoinGecko as ğŸ“ˆ CoinGecko API
    participant Blockchain as â›“ï¸ Blockchain.info
    
    User->>Browser: Enter miner model + electricity cost
    Browser->>Flask: POST /calculator/calculate
    
    Flask->>Auth: Verify session (optional)
    Auth-->>Flask: Session valid
    
    rect rgb(200, 220, 240)
    Note over Flask,CoinGecko: Parallel Data Collection
    
    par Fetch BTC Price
        Flask->>Cache: get('btc_price')
        alt Cache HIT (< 5 min)
            Cache-->>Flask: $92,477
        else Cache MISS
            Flask->>CoinGecko: GET /simple/price?ids=bitcoin
            CoinGecko-->>Flask: $92,477
            Flask->>Cache: set('btc_price', $92,477, 300s)
        end
    and Fetch Network Difficulty
        Flask->>Cache: get('network_difficulty')
        alt Cache HIT
            Cache-->>Flask: 152.27T
        else Cache MISS
            Flask->>Blockchain: GET /stats
            Blockchain-->>Flask: 152.27T
            Flask->>Cache: set('network_difficulty', 152.27T, 900s)
        end
    and Fetch Miner Specs
        Flask->>DB: SELECT * FROM miner_models WHERE name='S19 Pro'
        DB-->>Flask: Hashrate: 110 TH/s, Power: 3250W
    end
    end
    
    Flask->>Flask: Calculate Profitability
    Note over Flask: Daily Revenue = (110 TH/s / 991.6 EH/s) Ã— 450 BTC Ã— $92,477<br/>Daily Electricity = 3.25kW Ã— 24h Ã— $0.10 = $7.80<br/>Net Profit = Revenue - Cost<br/>ROI = Investment / (Net Profit Ã— 365)
    
    Flask->>DB: INSERT INTO calculation_history
    DB-->>Flask: Saved
    
    Flask->>Browser: Render calculator.html with results
    Browser->>User: ğŸ’° Display:<br/>Daily Profit: $45.23<br/>ROI: 245 days<br/>Break-even: 8.1 months
```

## 2. Background Telemetry Collection Flow

```mermaid
graph TB
    START([â° Scheduler Trigger<br/>Every 60 seconds])
    
    START --> LOCK{ğŸ”’ Acquire<br/>Distributed Lock}
    
    LOCK -->|Lock Acquired| QUERY[ğŸ“Š Query Active Miners<br/>WHERE status='active'<br/>AND cgminer_enabled=true]
    LOCK -->|Lock Held by Other Process| SKIP([Skip Execution<br/>Prevent Duplicates])
    
    QUERY --> COUNT{Miner Count}
    
    COUNT -->|8 miners| COLLECT[ğŸ”„ For Each Miner]
    COUNT -->|0 miners| END
    
    COLLECT --> CONNECT[ğŸ“¡ TCP Connect<br/>IP:4028]
    
    CONNECT --> SEND[ğŸ“¤ Send CGMiner Command<br/>{'command': 'summary'}]
    
    SEND --> RECEIVE{Response?}
    
    RECEIVE -->|âœ… Success| PARSE[ğŸ“‹ Parse Telemetry<br/>hashrate: 110.5 TH/s<br/>temp: 72.3Â°C<br/>power: 3200W<br/>fan: 5400 RPM]
    
    RECEIVE -->|âŒ Timeout| OFFLINE[âš ï¸ Mark Offline<br/>UPDATE status='offline'<br/>Send Alert]
    
    PARSE --> SAVE[ğŸ’¾ Save to Database<br/>INSERT INTO miner_telemetry]
    
    SAVE --> CACHE_UPDATE[âš¡ Update Cache<br/>set('miner_20_latest', data, 120s)]
    
    CACHE_UPDATE --> CHECK_THRESHOLDS{ğŸŒ¡ï¸ Check<br/>Thresholds}
    
    CHECK_THRESHOLDS -->|Temp > 80Â°C| ALERT[ğŸš¨ Send Alert Email]
    CHECK_THRESHOLDS -->|Normal| NEXT
    
    ALERT --> NEXT{More Miners?}
    OFFLINE --> NEXT
    
    NEXT -->|Yes| COLLECT
    NEXT -->|No| REFRESH[ğŸ”„ Refresh Lock Heartbeat]
    
    REFRESH --> RELEASE[ğŸ”“ Release Lock]
    
    RELEASE --> END([âœ… Collection Complete<br/>8 miners processed])
    
    style START fill:#4CAF50,stroke:#2E7D32,color:#fff
    style LOCK fill:#2196F3,stroke:#0D47A1,color:#fff
    style PARSE fill:#FF9800,stroke:#E65100,color:#fff
    style SAVE fill:#9C27B0,stroke:#4A148C,color:#fff
    style ALERT fill:#F44336,stroke:#b71c1c,color:#fff
    style END fill:#4CAF50,stroke:#2E7D32,color:#fff
```

## 3. Smart Curtailment Execution Flow

```mermaid
flowchart TB
    START([â° Scheduler: Check Pending Plans<br/>Every 60 seconds])
    
    START --> QUERY_PLANS[ğŸ“‹ Query Database<br/>SELECT * FROM curtailment_plans<br/>WHERE status='pending'<br/>AND scheduled_time <= NOW]
    
    QUERY_PLANS --> HAS_PLANS{Plans Found?}
    
    HAS_PLANS -->|No| END1([End])
    HAS_PLANS -->|Yes: 1 plan| LOAD_PLAN[ğŸ“„ Load Plan Details<br/>Site: HashPower MegaFarm<br/>Target: 5 MW reduction]
    
    LOAD_PLAN --> UPDATE_STATUS[ğŸ“ Update Status<br/>status = 'executing']
    
    UPDATE_STATUS --> QUERY_MINERS[ğŸ” Query All Active Miners<br/>SELECT * FROM hosting_miners<br/>WHERE site_id=5 AND status='active']
    
    QUERY_MINERS --> FETCH_TELEMETRY[ğŸ“Š Fetch Latest Telemetry<br/>For each miner]
    
    FETCH_TELEMETRY --> CALC_EFFICIENCY[âš™ï¸ Calculate Efficiency<br/>efficiency = hashrate / power]
    
    CALC_EFFICIENCY --> SORT[ğŸ“Š Sort by Efficiency ASC<br/>Worst performers first]
    
    SORT --> OPTIMIZE[ğŸ¯ PuLP Linear Programming<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Minimize: Hashrate Loss<br/>Subject to: Power â‰¥ 5000 kW<br/>Variables: shutdown[miner_id] binary]
    
    OPTIMIZE --> SOLUTION[âœ… Optimization Solution<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Miners to shutdown: 1538<br/>Power reduced: 5.00 MW<br/>Hashrate loss: 169.18 TH/s<br/>Strategy: Performance Priority]
    
    SOLUTION --> BEGIN_TX[ğŸ”„ BEGIN TRANSACTION]
    
    BEGIN_TX --> LOOP{For each<br/>recommended<br/>miner}
    
    LOOP -->|Miner #1| API_CALL[ğŸ“¡ API Call<br/>POST /api/miner/20/shutdown]
    
    API_CALL --> API_SUCCESS{Success?}
    
    API_SUCCESS -->|âœ… Yes| UPDATE_DB[ğŸ’¾ Update Database<br/>UPDATE hosting_miners<br/>SET status='curtailed'<br/>WHERE id=20]
    
    API_SUCCESS -->|âŒ Failed| LOG_ERROR[âš ï¸ Log Error<br/>Continue with others]
    
    UPDATE_DB --> LOG_OP[ğŸ“ Log Operation<br/>INSERT INTO miner_operation_log<br/>operation='curtailment_shutdown']
    
    LOG_OP --> LOOP
    LOG_ERROR --> LOOP
    
    LOOP -->|More miners| API_CALL
    LOOP -->|All processed| UPDATE_PLAN[ğŸ“ Update Plan<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>status = 'executed'<br/>executed_at = NOW<br/>miners_affected = 1538<br/>power_reduced = 5.00]
    
    UPDATE_PLAN --> COMMIT[âœ… COMMIT TRANSACTION]
    
    COMMIT --> NOTIFY[ğŸ“§ Send Notification<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>To: Farm Manager<br/>Subject: Curtailment Executed<br/>Body: 5 MW reduced, 1538 miners]
    
    NOTIFY --> SCHEDULE_RECOVERY[â° Schedule Auto Recovery<br/>recovery_time = executed_at + 4 hours]
    
    SCHEDULE_RECOVERY --> END2([âœ… Curtailment Complete])
    
    style START fill:#4CAF50,stroke:#2E7D32,color:#fff
    style OPTIMIZE fill:#FF9800,stroke:#E65100,color:#fff
    style SOLUTION fill:#2196F3,stroke:#0D47A1,color:#fff
    style COMMIT fill:#4CAF50,stroke:#2E7D32,color:#fff
    style NOTIFY fill:#9C27B0,stroke:#4A148C,color:#fff
```

## 4. Multi-Exchange Data Aggregation

```mermaid
graph TB
    TRIGGER([â° Scheduler Trigger<br/>Every 15 minutes])
    
    TRIGGER --> START_COLLECT[ğŸš€ Start Collection]
    
    START_COLLECT --> PARALLEL{ğŸ”„ Parallel API Calls<br/>ThreadPoolExecutor}
    
    subgraph "Exchange 1: Binance"
        BINANCE_START[ğŸ“¡ Binance API Call]
        BINANCE_START --> BINANCE_FETCH[GET /api/v3/ticker/24hr<br/>symbol=BTCUSDT]
        BINANCE_FETCH --> BINANCE_RESULT[ğŸ“Š Result:<br/>Price: $92,477<br/>Volume: 21,567 BTC]
    end
    
    subgraph "Exchange 2: OKX"
        OKX_START[ğŸ“¡ OKX API Call]
        OKX_START --> OKX_FETCH[GET /api/v5/market/ticker<br/>instId=BTC-USDT]
        OKX_FETCH --> OKX_RESULT[ğŸ“Š Result:<br/>Price: $92,475<br/>Volume: 18,234 BTC]
    end
    
    subgraph "Exchange 3: Deribit"
        DERIBIT_START[ğŸ“¡ Deribit API Call]
        DERIBIT_START --> DERIBIT_FETCH[GET /api/v2/public/get_index<br/>currency=BTC]
        DERIBIT_FETCH --> DERIBIT_RESULT[ğŸ“Š Result:<br/>Index: $92,478<br/>Options Volume: 3,456]
    end
    
    subgraph "Exchange 4: Bybit"
        BYBIT_START[ğŸ“¡ Bybit API Call]
        BYBIT_START --> BYBIT_FETCH[GET /v5/market/tickers<br/>symbol=BTCUSDT]
        BYBIT_FETCH --> BYBIT_RESULT[ğŸ“Š Result:<br/>Price: $92,476<br/>Volume: 15,890 BTC]
    end
    
    PARALLEL --> BINANCE_START
    PARALLEL --> OKX_START
    PARALLEL --> DERIBIT_START
    PARALLEL --> BYBIT_START
    
    BINANCE_RESULT --> AGGREGATE
    OKX_RESULT --> AGGREGATE
    DERIBIT_RESULT --> AGGREGATE
    BYBIT_RESULT --> AGGREGATE
    
    AGGREGATE[ğŸ“Š Aggregate Results<br/>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”<br/>Average Price: $92,476.50<br/>Total Volume: 55,691 BTC<br/>Data Completeness: 100%<br/>Sources: 4/4 exchanges]
    
    AGGREGATE --> SAVE_DB[(ğŸ’¾ Save to Database<br/>INSERT INTO market_analytics)]
    
    SAVE_DB --> CALC_INDICATORS[ğŸ“ˆ Calculate Indicators<br/>RSI, MACD, Bollinger Bands]
    
    CALC_INDICATORS --> UPDATE_CACHE[âš¡ Update Cache<br/>set('latest_btc_price', $92,476.50, 300s)]
    
    UPDATE_CACHE --> END([âœ… Collection Complete])
    
    style PARALLEL fill:#2196F3,stroke:#0D47A1,color:#fff
    style AGGREGATE fill:#FF9800,stroke:#E65100,color:#fff
    style CALC_INDICATORS fill:#9C27B0,stroke:#4A148C,color:#fff
    style END fill:#4CAF50,stroke:#2E7D32,color:#fff
```

## Data Flow Summary

| Flow Type | Frequency | Data Sources | Cache TTL | Performance |
|-----------|-----------|--------------|-----------|-------------|
| User Requests | On-demand | Database + APIs | 5-15 min | < 200ms (cached) |
| Telemetry Collection | Every 60s | CGMiner APIs | 2 min | ~8 miners/sec |
| Market Data | Every 15 min | 4 exchanges | 5 min | ~3s total |
| Curtailment Execution | On-schedule | Database + Optimizer | N/A | ~30s for 1538 miners |

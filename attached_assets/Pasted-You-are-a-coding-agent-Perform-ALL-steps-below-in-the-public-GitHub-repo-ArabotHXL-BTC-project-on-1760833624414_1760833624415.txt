You are a coding agent. Perform ALL steps below in the public GitHub repo `ArabotHXL/BTC_project` on a new branch and open a PR. Do NOT remove or break existing files; add content non-destructively.

BRANCH
- Create branch: feat/ops-dev-stack

GOALS
1) Add a one-command dev stack (docker-compose) with: FastAPI API, strategy worker, Postgres, Redis, Prometheus, Grafana.
2) Add a unified miner adapter layer for WhatsMiner / Braiins OS+ / Avalon / cgminer(4028).
3) Add a minimal YAML-driven strategy engine with DB audit + Prometheus metrics.
4) Add README, .env.example, Makefile targets, monitoring config, minimal CI.
5) Keep all current repo content intact. If a file already exists, merge non-destructively (append sections).

FILE OPERATIONS (create directories as needed; add empty __init__.py in new python dirs)
1) Create `.env.example` with EXACT content:
----
API_PORT=8000
WORKER_INTERVAL_SEC=30

POSTGRES_HOST=db
POSTGRES_PORT=5432
POSTGRES_DB=btc_project
POSTGRES_USER=btc
POSTGRES_PASSWORD=btcpass

REDIS_URL=redis://redis:6379/0

JWT_SECRET=dev-secret
ALLOWED_SUBNETS=0.0.0.0/0

WHATS_DEV_MODE=true
BOS_GRPC_TIMEOUT_SEC=3
CGMINER_PORT=4028
----

2) Create `docker-compose.dev.yml` with EXACT content:
----
version: "3.9"
services:
  api:
    build: .
    command: uvicorn api.main:app --host 0.0.0.0 --port ${API_PORT}
    env_file: .env
    ports: ["${API_PORT}:${API_PORT}"]
    depends_on: [db, redis]
  worker:
    build: .
    command: python modules/strategy/runner.py
    env_file: .env
    depends_on: [api, db, redis]
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports: ["5432:5432"]
    volumes:
      - pgdata:/var/lib/postgresql/data
  redis:
    image: redis:7
    ports: ["6379:6379"]
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
    ports: ["9090:9090"]
    depends_on: [api, worker]
  grafana:
    image: grafana/grafana:latest
    ports: ["3000:3000"]
    depends_on: [prometheus]
volumes:
  pgdata:
----

3) Update or create `Makefile`. If it exists, APPEND these targets verbatim (keep existing ones):
----
.PHONY: up down logs seed lint test fmt
up: ; docker compose -f docker-compose.dev.yml --env-file .env up -d --build
down: ; docker compose -f docker-compose.dev.yml down -v
logs: ; docker compose -f docker-compose.dev.yml logs -f --tail=200
seed: ; python migrations/seed.py
lint: ; ruff check . || true
fmt: ; ruff format .
test: ; pytest -q || true
----

4) Create `monitoring/prometheus.yml`:
----
global:
  scrape_interval: 10s
scrape_configs:
  - job_name: api
    static_configs: [{ targets: ["api:8000"] }]
  - job_name: worker
    static_configs: [{ targets: ["worker:8001"] }]
----

5) Create or append to `requirements.txt` (append these lines if file exists; avoid duplicates):
----
fastapi
uvicorn
prometheus-client
psycopg2-binary
SQLAlchemy
PyYAML
httpx
ruff
----

6) Create or update `Dockerfile`. If file exists, ensure it contains at least these steps (merge carefully, do not remove important existing steps). Result must be buildable:
----
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt \
 && apt-get update \
 && apt-get install -y grpcurl netcat-openbsd \
 && rm -rf /var/lib/apt/lists/*
COPY . .
EXPOSE 8000
----

7) Create `api/main.py` (create `api/` and `api/__init__.py` if missing):
----
from fastapi import FastAPI
from fastapi.responses import Response
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST, Counter
from modules.miner_adapters.facade import read_stats, set_power_w, set_power_pct, set_mode
from modules.strategy.audit import last_audits

app = FastAPI(title="HashInsight Ops API")
CMD_COUNTER = Counter("ops_commands_total", "count of adapter commands", ["cmd"])

@app.get("/health")
def health(): return {"status":"ok"}

@app.get("/metrics")
def metrics():
    data = generate_latest()
    return Response(content=data, media_type=CONTENT_TYPE_LATEST)

@app.get("/miners/{ip}/stats")
def miners_stats(ip: str):
    CMD_COUNTER.labels("read_stats").inc()
    return read_stats(ip)

@app.post("/miners/{ip}/power_w/{watts}")
def miners_power_w(ip: str, watts: int):
    CMD_COUNTER.labels("set_power_w").inc()
    return set_power_w(ip, watts)

@app.post("/miners/{ip}/power_pct/{pct}")
def miners_power_pct(ip: str, pct: int):
    CMD_COUNTER.labels("set_power_pct").inc()
    return set_power_pct(ip, pct)

@app.post("/miners/{ip}/mode/{mode}")
def miners_mode(ip: str, mode: str):
    CMD_COUNTER.labels("set_mode").inc()
    return set_mode(ip, mode)

@app.get("/audit/latest")
def audit_latest(): return last_audits(limit=50)
----

8) Create adapter package with files:

`modules/miner_adapters/__init__.py`
----
# empty
----

`modules/miner_adapters/facade.py`
----
from .cgminer import cgminer_read_stats
from .whatsminer import wm_set_power_w, wm_set_power_pct, wm_set_mode, wm_read_summary
from .bos_plus import bos_set_power_w, bos_read_summary
from .avalon import ava_set_mode, ava_set_power_level, ava_read_stats

PREF_ORDER = ["whatsminer","bosplus","avalon","cgminer"]

def read_stats(ip: str):
    for t in PREF_ORDER:
        try:
            if t=="whatsminer": return {"type":t, "data": wm_read_summary(ip)}
            if t=="bosplus":    return {"type":t, "data": bos_read_summary(ip)}
            if t=="avalon":     return {"type":t, "data": ava_read_stats(ip)}
        except Exception:
            pass
    return {"type":"cgminer", "data": cgminer_read_stats(ip)}

def set_power_w(ip: str, watts: int):
    try: return wm_set_power_w(ip, watts)
    except Exception: pass
    try: return bos_set_power_w(ip, watts)
    except Exception: pass
    return {"ok": False, "msg": "no writable adapter available"}

def set_power_pct(ip: str, pct: int):
    try: return wm_set_power_pct(ip, pct)
    except Exception: pass
    return {"ok": False, "msg": "no writable adapter available"}

def set_mode(ip: str, mode: str):
    try: return wm_set_mode(ip, mode)
    except Exception: pass
    try: return ava_set_mode(ip, mode)
    except Exception: pass
    return {"ok": False, "msg": "no writable adapter available"}
----

`modules/miner_adapters/cgminer.py`
----
import socket, json, os
PORT = int(os.getenv("CGMINER_PORT","4028"))

def _send(ip, payload: str, timeout=3):
    s=socket.socket(); s.settimeout(timeout); s.connect((ip, PORT))
    s.sendall(payload.encode()); buf=b""
    while True:
        c=s.recv(65535)
        if not c: break
        buf+=c
    s.close()
    return buf.decode(errors="ignore")

def cgminer_read_stats(ip: str):
    try:
        return json.loads(_send(ip, json.dumps({"command":"stats"})))
    except Exception:
        raw=_send(ip, "stats")
        return {"raw":raw}
----

`modules/miner_adapters/whatsminer.py`
----
import os, json, socket
DEV = os.getenv("WHATS_DEV_MODE","true").lower()=="true"
PORT = 4028

def _send_json(ip, obj, timeout=3):
    s=socket.socket(); s.settimeout(timeout); s.connect((ip, PORT))
    s.sendall(json.dumps(obj).encode()); resp = s.recv(65535); s.close()
    try: return json.loads(resp.decode())
    except: return {"raw": resp.decode(errors="ignore")}

def wm_read_summary(ip: str):
    return _send_json(ip, {"cmd":"summary"})

def wm_set_power_w(ip: str, watts: int):
    if DEV: return {"ok": True, "dev": True, "cmd":"adjust_power_limit", "watts":watts}
    raise RuntimeError("WhatsMiner encrypted write not implemented")  # TODO

def wm_set_power_pct(ip: str, pct: int):
    if DEV: return {"ok": True, "dev": True, "cmd":"set_power_pct", "pct":pct}
    raise RuntimeError("WhatsMiner encrypted write not implemented")  # TODO

def wm_set_mode(ip: str, mode: str):
    if DEV: return {"ok": True, "dev": True, "cmd":"set_"+mode}
    raise RuntimeError("WhatsMiner encrypted write not implemented")  # TODO
----

`modules/miner_adapters/bos_plus.py`
----
import os, subprocess, json
TIMEOUT=str(int(float(os.getenv("BOS_GRPC_TIMEOUT_SEC","3"))))

def _grpc(ip, service, method, data=None, token=None):
    args=["grpcurl","-plaintext",f"-max-time={TIMEOUT}"]
    if data: args+=["-d", json.dumps(data)]
    if token: args+=["-H", f"authorization:{token}"]
    args.append(f"{ip}:50051"); args.append(f"{service}/{method}")
    return subprocess.check_output(args, text=True)

def bos_read_summary(ip: str):
    try:
        out=_grpc(ip,"braiins.bos.v1.MonitoringService","GetSummary")
        return json.loads(out)
    except Exception as e:
        return {"ok":False,"error":str(e)}

def bos_set_power_w(ip: str, watts: int, token=None):
    try:
        out=_grpc(ip,"braiins.bos.v1.PerformanceService","SetPowerTarget",
                  {"powerTarget":{"watts":int(watts)}}, token=token)
        return {"ok":True,"resp":out}
    except Exception as e:
        return {"ok":False,"error":str(e)}
----

`modules/miner_adapters/avalon.py`
----
import socket, os
PORT = int(os.getenv("CGMINER_PORT","4028"))

def _send_str(ip, payload, timeout=3):
    s=socket.socket(); s.settimeout(timeout); s.connect((ip, PORT))
    s.sendall(payload.encode()); resp=s.recv(65535); s.close()
    return resp.decode(errors="ignore")

def ava_read_stats(ip: str): return {"raw": _send_str(ip, "stats")}

def ava_set_mode(ip: str, mode: str):
    m = {"low":"0","normal":"1","high":"2"}.get(mode, "1")
    return {"raw": _send_str(ip, f"ascset|0,workmode,{m}")}

def ava_set_power_level(ip: str, level: int):
    return {"raw": _send_str(ip, f"ascset|0,power-level-set,{int(level)}")}
----

9) Create strategy package:

`modules/strategy/__init__.py`
----
# empty
----

`modules/strategy/config.sample.yml`
----
rules:
  - name: Curtail on high price
    when:
      price_usd_per_kwh: { "gt": 0.07 }
    then:
      set_power_pct: 70
  - name: Overheat protect
    when:
      chip_tmax: { "gt": 90 }
    then:
      set_mode: low
targets:
  - ip: 10.10.0.101
  - ip: 10.10.0.102
----

`modules/strategy/audit.py`
----
import os, psycopg2

def _conn():
    return psycopg2.connect(
        host=os.getenv("POSTGRES_HOST","db"),
        port=os.getenv("POSTGRES_PORT","5432"),
        dbname=os.getenv("POSTGRES_DB","btc_project"),
        user=os.getenv("POSTGRES_USER","btc"),
        password=os.getenv("POSTGRES_PASSWORD","btcpass"),
    )

def ensure_schema():
    with _conn() as c:
        cur=c.cursor()
        cur.execute("""
        create table if not exists audit_log(
          id bigserial primary key,
          ts timestamptz default now(),
          target_ip text, action text, before jsonb, after jsonb, result jsonb
        );""")
        c.commit()

def write_audit(ip, action, before, after, result):
    with _conn() as c:
        cur=c.cursor()
        cur.execute(
          "insert into audit_log(target_ip,action,before,after,result) values (%s,%s,%s,%s,%s)",
          (ip, action, before, after, result)
        ); c.commit()

def last_audits(limit=50):
    with _conn() as c:
        cur=c.cursor()
        cur.execute("select ts,target_ip,action,result from audit_log order by ts desc limit %s",(limit,))
        rows=cur.fetchall()
        return [{"ts":str(r[0]),"ip":r[1],"action":r[2],"result":r[3]} for r in rows]
----

`modules/strategy/runner.py`
----
import os, time, yaml
from prometheus_client import start_http_server, Gauge
from modules.miner_adapters.facade import read_stats, set_power_w, set_power_pct, set_mode
from .audit import ensure_schema, write_audit

INTERVAL = int(os.getenv("WORKER_INTERVAL_SEC","30"))
CFG_PATH = os.getenv("STRATEGY_CONFIG","modules/strategy/config.sample.yml")

ACTIONS = Gauge("strategy_actions_count","applied actions",["rule","action"])

def _read_cfg():
    with open(CFG_PATH,"r") as f: return yaml.safe_load(f)

def _match(val, cond: dict):
    if "gt" in cond and not (val > cond["gt"]): return False
    if "lt" in cond and not (val < cond["lt"]): return False
    return True

def main():
    ensure_schema()
    start_http_server(8001)
    while True:
        cfg=_read_cfg()
        for t in cfg.get("targets",[]):
            ip=t["ip"]
            stats=read_stats(ip)  # TODO: parse temp, etc., from stats if available
            price= t.get("price_usd_per_kwh", 0.05)
            chip_tmax= t.get("chip_tmax", 70)
            ctx={"price_usd_per_kwh":price, "chip_tmax":chip_tmax, "stats":stats}
            for r in cfg.get("rules",[]):
                ok=True
                for k, cd in r.get("when",{}).items():
                    ok = ok and _match(ctx.get(k,0), cd)
                if not ok: continue
                if "set_power_pct" in r["then"]:
                    pct = int(r["then"]["set_power_pct"])
                    result=set_power_pct(ip, pct)
                    write_audit(ip, "set_power_pct", {"ctx":ctx}, {"pct":pct}, result)
                    ACTIONS.labels(r["name"],"set_power_pct").inc()
                if "set_power_w" in r["then"]:
                    w = int(r["then"]["set_power_w"])
                    result=set_power_w(ip, w)
                    write_audit(ip, "set_power_w", {"ctx":ctx}, {"watts":w}, result)
                    ACTIONS.labels(r["name"],"set_power_w").inc()
                if "set_mode" in r["then"]:
                    m = str(r["then"]["set_mode"])
                    result=set_mode(ip, m)
                    write_audit(ip, "set_mode", {"ctx":ctx}, {"mode":m}, result)
                    ACTIONS.labels(r["name"],"set_mode").inc()
        time.sleep(INTERVAL)

if __name__=="__main__": main()
----

10) Create `migrations/seed.py`:
----
from modules.strategy.audit import ensure_schema
if __name__=="__main__":
    ensure_schema(); print("DB seeded.")
----

11) Update top-level `README.md`. If file exists, APPEND this section at the TOP; if not, create with this content:
----
# HashInsight Ops — Dev Stack (API + Strategy + Monitoring)

## Quickstart
```bash
cp .env.example .env
make up
make seed
curl localhost:8000/health
curl localhost:8000/metrics | head -n 5
Miner Adapters
cgminer (read-only stats on 4028)

WhatsMiner (dev-mode stubs for writes; set WHATS_DEV_MODE=false after implementing encrypted writer)

Braiins OS+ (grpcurl SetPowerTarget)

Avalon (ascset workmode/power-level)

Strategy Engine
Edit modules/strategy/config.sample.yml. Worker applies rules every $WORKER_INTERVAL_SEC seconds.

Monitoring & Audit
Prometheus scrapes API /metrics and worker (8001). Audits stored in Postgres table audit_log.
Create CI: .github/workflows/ci.yml:

name: ci
on: [push, pull_request]
jobs:
python:
runs-on: ubuntu-latest
steps:
- uses: actions/checkout@v4
- uses: actions/setup-python@v5
with: { python-version: "3.11" }
- run: pip install -r requirements.txt
- run: python -m py_compile $(git ls-files '*.py') || true
VALIDATION (run locally in the PR description as proof)

Commands to run after merge or locally:

bash
复制代码
cp .env.example .env
make up
make seed
curl localhost:8000/health
curl localhost:8000/metrics | head -n 5
# Optional: open http://localhost:9090 and http://localhost:3000
# Replace <MINER_IP>:
curl "http://localhost:8000/miners/<MINER_IP>/stats"
COMMIT & PR

Commit message: feat(ops-dev): add dev stack (compose, adapters, strategy, audit, monitoring, ci)

Open a PR to main titled: Ops Dev Stack (P0–P4): compose + adapters + strategy + monitoring

PR description: list added files, how to start, and TODO:

Implement WhatsMiner encrypted writer (get_token/sign/AES-256/enc frame)

Add power-change slope limiting & rollback

Add Grafana dashboard JSON

Add API auth (JWT/rate-limit/allow-subnets)
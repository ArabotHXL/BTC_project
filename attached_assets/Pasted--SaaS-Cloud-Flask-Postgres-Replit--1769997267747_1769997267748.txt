你是资深矿场 SaaS 云端（Cloud）工程负责人，擅长 Flask/Postgres/多租户/审计/控制平面/托管对账。请在 Replit 环境下对当前仓库做“最小破坏式”增强：保持单体可运行，但补齐工程化与可证明性，优先托管 PoC（SLA/对账透明、争议证据包），并为未来私有化做好准备（docker-compose 占位即可）。

========================
【已知现状（来自代码扫描结果，默认可信但需要复核）】
========================
✅ 已完成（不要推翻）：
- RBAC：common/rbac.py（完整角色/权限矩阵）
- ABAC：check_site_access() 等 tenant/site 过滤逻辑
- 控制平面状态机：models_remote_control.py（PENDING_APPROVAL→QUEUED→...）
- 远程控制命令：api/remote_control_api.py / api/control_plane_api.py
- Telemetry 四层：TelemetryRaw24h / TelemetryLive / TelemetryHistory5min / MinerTelemetryHistory
- SchedulerLock：已有单实例锁在多个 scheduler 服务中使用
- 客户门户只读：customer 角色只读
- Health：/health /health/deep /ready /alive
- 审计日志：audit/audit_logger.py + AuditEvent 模型
- Hash chain：models_control_plane.py（AuditEvent with prev_hash）
- hosting 模块：modules/hosting/routes.py
- edge_collector / collector_api.py，多 remote 支持（remote_id 字段）
- 设备加密 / 凭证保护 / AI闭环 / 自动执行 / 限电调度等已有

⚠️ 部分完成（需补齐）：
- 审计 hash chain 校验脚本（verify_audit_chain 缺）
- 证据包导出（缺“停机归因+时间线+审计链校验”完整包）
- telemetry 聚合层幂等 upsert 需验证（live upsert 已有，但要确认 bucket 层）
- 越权验证脚本缺（证明客户隔离 403）

❌ 未完成（必须做的工程化门槛）：
- Application Factory：缺 create_app()
- Alembic 迁移：仍用 db.create_all()
- Google/Microsoft OIDC：未做（先放 P1 计划，不强制本轮落码）
- mTLS/VPN 开关：未做（P1 计划）
- docker-compose.yml 占位：未做
- .env.example：未做
- worker/scheduler 分离运行模式：部分（Replit 先用多进程/子进程方式即可）

========================
【目标与硬约束（必须遵守）】
========================
1) 当前继续 Replit 单体运行（不要拆微服务）；未来需要私有化（Docker Compose/K8s）。
2) 数据库维持现状（不要强推 TimescaleDB）。
3) 单站 5000 miners；多 Remote 汇总（remote_id + source_seq + received_at + 幂等键）。
4) 多租户 Tenant + 客户门户只读必须“可证明”隔离（403 验证脚本）。
5) 审计必须不可篡改（hash chain），并提供 verify 工具能 PASS/FAIL。
6) 不破坏现有 API 路由与 collector/remote 协议；只增不删。
7) 不大改 UI，不做“漂亮重构”，以可交付/可验收为第一优先级。

========================
【本轮只做 P0（必须落代码），P1 只写计划不实现】
========================

P0-1：实现 verify_audit_chain 工具（CLI + 可选 API）
- 新增 scripts/verify_audit_chain.py
- 输入：tenant_id/site_id + 时间范围（或 event_id 范围）
- 输出：PASS/FAIL；FAIL 时打印断链点（event_id、prev_hash、expected、actual）
- 要求：hash 计算必须 canonical json（固定字段序与序列化规则）
- 同时加最小 DB 约束/触发器或应用层双保险：AuditEvent append-only（禁止 update/delete）

验收：
Given 一段审计事件范围
When 运行 verify_audit_chain
Then 输出 PASS；若手动篡改任一事件则 FAIL 且定位断点

P0-2：实现“越权验证脚本”（客户隔离证明）
- 新增 scripts/verify_tenant_isolation.py
- 用 customer token（或测试用户）访问非本租户 site/tenant 的资源：
  - telemetry 查询
  - reports/hosting 账期报表
  - workorders（如有）
  - commands（如有）
- 预期全部 403；输出 PASS/FAIL 清单

验收：
Given customer 属于 tenant A
When 访问 tenant B 的 site_id
Then 100% 返回 403（脚本输出 PASS）

P0-3：实现 telemetry 幂等性验证脚本 + 修复（若发现重复）
- 新增 scripts/verify_telemetry_idempotency.py
- 构造同一 miner_id + 同一 bucket（按你当前 5min 或 1m 聚合口径）重复上送 N 次
- 预期：history 行数不增加；聚合值不漂移；out-of-order 不污染口径（除非标记修正写入并入审计）

验收：
Given N 次重复 payload
When 入库完成
Then 聚合层行数恒定且指标一致

P0-4：实现“证据包导出 v1”（托管 PoC 核心）
要求：在现有 SLA 报表基础上新增 “Evidence Pack v1”
- 内容至少包含 4 部分：
  1) 账期范围 + 口径声明（planned/unplanned、缺口处理、聚合粒度）
  2) 停机分钟计算（按 miner/按 site 汇总）
  3) 事件时间线（alerts/workorders/commands/audit events 摘要）
  4) 审计链校验结果（verify_audit_chain 的 PASS/FAIL 输出摘要 + hash 摘要）
- 交付形式：先做 zip（CSV/JSON），可选再做 PDF（不强制）
- 提供 API：GET /api/v1/hosting/evidence_pack?site_id=...&from=...&to=...
- 该接口必须走 ABAC 校验（客户只可下载自己租户/站点的）

验收：
Given 任意账期
When 请求 evidence_pack
Then 返回可下载 zip；包含以上4块内容；审计校验 PASS；越权访问 403

P0-5：Application Factory（create_app）最小改造
- 新增 app/__init__.py：create_app()
- 将全局初始化（db/init/blueprints）迁入 create_app + init_app
- 保持现有入口 app.py 可用：app.py 只负责调用 create_app()
- scheduler/后台任务初始化必须放到明确入口（run_scheduler 或 run_all），并使用现有 SchedulerLock 防重复

验收：
- 冷启动 0 ImportError
- 通过现有 run 命令能在 Replit 启动成功
- 多进程情况下 scheduler 不重复执行（日志可证明）

P0-6：Alembic baseline（迁移体系接管 db.create_all）
- 引入 Alembic，生成 baseline migration 与当前模型对齐
- 对现有数据库提供“安全接管”步骤（alembic stamp head）
- 禁止继续依赖 db.create_all 作为升级路径（保留兼容但默认不走）

验收：
- 空库：alembic upgrade head 可建出当前结构
- 现有库：alembic stamp head 后可继续增量迁移

P0-7：.env.example + 配置 fail-fast
- 新增 .env.example：列出所有必须变量（DATABASE_URL、SECRET_KEY、TOKEN_SALT、等）
- 启动时校验缺项：缺关键变量直接启动失败（提示清楚）
- 禁止任何密钥硬编码

P0-8：docker-compose.yml 占位 + docs
- 新增 docker-compose.yml（web/worker/scheduler/db/redis 占位即可）
- docs/DEPLOYMENT.md：说明未来私有化运行方式与注意事项（不要求现在能跑）
- Replit 仍以单体为主

Replit 运行模式（P0 可落地的最小形态）：
- 增加三个入口脚本：run_web.py / run_worker.py / run_scheduler.py
- 增加 run_all.py：用 subprocess 启动 web+worker+scheduler（Replit Run 用 run_all）
- 注意：必须依赖 SchedulerLock/worker lock 防重复

========================
【P1（只输出计划，不落代码）】
========================
- Google/Microsoft OIDC + 保留邮箱登录（统一 user + 多 identity 绑定）
- mTLS/VPN 开关（可配置且可审计证明）
- 更完善指标（ingest_success_rate、ingest_latency_p95、queue_lag、command_ack_latency）

========================
【输出要求（严格按顺序）】
========================
1) Repo 扫描结果：入口文件、蓝图/路由、模型位置、鉴权点、任何 import 缺失清单
2) P0 变更文件清单（新增/修改哪些文件）
3) 分 commit 输出实施步骤：每一步做什么、为什么、如何验证
4) 给出运行/验证命令：
   - Replit 如何启动（run_all）
   - 3 个 scripts 如何跑（verify_audit_chain / verify_tenant_isolation / verify_telemetry_idempotency）
   - evidence_pack 如何调用（curl 示例）
5) 风险与回滚策略：任何一步失败如何回退

现在开始执行：只做 P0，不做 UI 大改，不引入微服务，不破坏现有 API/collector/remote 协议。

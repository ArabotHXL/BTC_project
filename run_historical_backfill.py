"""
è‡ªåŠ¨è¿è¡Œå†å²æ•°æ®æ‰©å±• - è·å–2å¹´å†å²æ•°æ®
"""
from historical_data_backfill import HistoricalDataBackfill
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def run_extended_backfill():
    """è¿è¡Œæ‰©å±•å†å²æ•°æ®å›å¡«"""
    backfill = HistoricalDataBackfill()
    
    logger.info("å¼€å§‹æ‰©å±•å†å²æ•°æ® - è·å–2å¹´æ•°æ®...")
    
    # æ‰©å±•730å¤©ï¼ˆ2å¹´ï¼‰å†å²æ•°æ®
    success = backfill.extend_historical_data(730)
    
    if success:
        print("âœ… å†å²æ•°æ®æ‰©å±•æˆåŠŸï¼")
        
        # æ˜¾ç¤ºæœ€æ–°ç»Ÿè®¡
        conn = backfill.get_connection()
        cursor = conn.cursor()
        cursor.execute("""
            SELECT 
                COUNT(*) as total_records,
                MIN(DATE(recorded_at)) as earliest_date,
                MAX(DATE(recorded_at)) as latest_date,
                COUNT(DISTINCT DATE(recorded_at)) as unique_days,
                COUNT(CASE WHEN btc_volume_24h > 0 THEN 1 END) as volume_records
            FROM market_analytics
        """)
        total, earliest, latest, unique_days, volume_records = cursor.fetchone()
        
        print(f"\nğŸ“Š æ‰©å±•åæ•°æ®åº“ç»Ÿè®¡ï¼š")
        print(f"   æ€»è®°å½•æ•°: {total:,}")
        print(f"   æ—¶é—´è·¨åº¦: {earliest} åˆ° {latest}")
        print(f"   è¦†ç›–å¤©æ•°: {unique_days}")
        print(f"   å¹³å‡æ¯å¤©: {total/unique_days:.1f}æ¡è®°å½•")
        print(f"   æˆäº¤é‡è®°å½•: {volume_records:,} ({volume_records/total*100:.1f}%)")
        
        cursor.close()
        conn.close()
        
        return True
    else:
        print("âŒ å†å²æ•°æ®æ‰©å±•å¤±è´¥")
        return False

if __name__ == "__main__":
    run_extended_backfill()
"""
HashInsight CDC Platform - Outbox Publisher
Transactional Outboxæ¨¡å¼å®ç°ï¼Œç¡®ä¿äº‹ä»¶ä¸ä¸šåŠ¡æ“ä½œçš„åŸå­æ€§
"""
import os
import logging
import uuid
from datetime import datetime
from typing import Dict, Any, Optional
from sqlalchemy import text
from sqlalchemy.exc import SQLAlchemyError

logger = logging.getLogger(__name__)

class OutboxPublisher:
    """
    Outboxäº‹ä»¶å‘å¸ƒå™¨
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. åœ¨æ•°æ®åº“äº‹åŠ¡å†…å†™å…¥event_outboxè¡¨
    2. æ”¯æŒå¹‚ç­‰æ€§ï¼ˆidempotency_keyï¼‰
    3. è‡ªåŠ¨è®¾ç½®tenant_idï¼ˆå¤šç§Ÿæˆ·æ”¯æŒï¼‰
    4. Debezium CDCä¼šè‡ªåŠ¨æ•è·å¹¶å‘å¸ƒåˆ°Kafka
    """
    
    def __init__(self, db):
        """
        åˆå§‹åŒ–Outboxå‘å¸ƒå™¨
        
        å‚æ•°:
            db: SQLAlchemyæ•°æ®åº“å®ä¾‹
        """
        self.db = db
        logger.info("âœ… OutboxPublisher initialized")
    
    def publish(
        self,
        kind: str,
        user_id: str,
        payload: Dict[str, Any],
        entity_id: Optional[str] = None,
        tenant_id: str = 'default',
        idempotency_key: Optional[str] = None
    ) -> Optional[str]:
        """
        å‘å¸ƒäº‹ä»¶åˆ°Outboxè¡¨ï¼ˆåœ¨å½“å‰äº‹åŠ¡å†…ï¼‰
        
        å‚æ•°:
            kind: äº‹ä»¶ç±»å‹ï¼ˆå¦‚ 'miner.added', 'treasury.trade_executed'ï¼‰
            user_id: ç”¨æˆ·IDï¼ˆä½œä¸ºKafkaæ¶ˆæ¯é”®ï¼Œä¿è¯åŒä¸€ç”¨æˆ·çš„äº‹ä»¶é¡ºåºï¼‰
            payload: äº‹ä»¶è´Ÿè½½ï¼ˆJSONï¼‰
            entity_id: å®ä½“IDï¼ˆå¯é€‰ï¼‰
            tenant_id: ç§Ÿæˆ·IDï¼ˆé»˜è®¤'default'ï¼‰
            idempotency_key: å¹‚ç­‰é”®ï¼ˆå¯é€‰ï¼Œé˜²æ­¢é‡å¤äº‹ä»¶ï¼‰
        
        è¿”å›:
            äº‹ä»¶IDæˆ–Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        
        ç¤ºä¾‹:
            >>> outbox.publish(
            ...     kind='miner.added',
            ...     user_id='user123',
            ...     payload={'miner_id': 'miner456', 'hashrate': 100},
            ...     entity_id='miner456',
            ...     idempotency_key='add_miner_user123_miner456'
            ... )
        """
        try:
            # ç”Ÿæˆäº‹ä»¶ID
            event_id = str(uuid.uuid4())
            
            # å¦‚æœæœªæä¾›å¹‚ç­‰é”®ï¼Œä½¿ç”¨äº‹ä»¶IDä½œä¸ºå¹‚ç­‰é”®
            if not idempotency_key:
                idempotency_key = event_id
            
            # å‡†å¤‡SQLå‚æ•°
            params = {
                'id': event_id,
                'kind': kind,
                'user_id': user_id,
                'tenant_id': tenant_id,
                'entity_id': entity_id,
                'payload': payload,  # SQLAlchemyä¼šè‡ªåŠ¨è½¬æ¢ä¸ºJSONB
                'idempotency_key': idempotency_key,
                'created_at': datetime.utcnow(),
                'processed': False
            }
            
            # æ’å…¥event_outboxè¡¨
            # ä½¿ç”¨ ON CONFLICT DO NOTHING å®ç°å¹‚ç­‰æ€§
            sql = text("""
                INSERT INTO event_outbox (
                    id, kind, user_id, tenant_id, entity_id, 
                    payload, idempotency_key, created_at, processed
                )
                VALUES (
                    :id, :kind, :user_id, :tenant_id, :entity_id,
                    :payload::jsonb, :idempotency_key, :created_at, :processed
                )
                ON CONFLICT (idempotency_key) DO NOTHING
                RETURNING id
            """)
            
            result = self.db.session.execute(sql, params)
            inserted_id = result.scalar()
            
            if inserted_id:
                logger.info(
                    f"ğŸ“¤ Event published to outbox: "
                    f"kind={kind}, user={user_id}, tenant={tenant_id}, id={event_id}"
                )
                return event_id
            else:
                logger.warning(
                    f"âš ï¸ Duplicate event ignored (idempotency): "
                    f"kind={kind}, key={idempotency_key}"
                )
                return None
        
        except SQLAlchemyError as e:
            logger.error(f"âŒ Failed to publish event to outbox: {e}")
            raise
    
    def publish_batch(
        self,
        events: list[Dict[str, Any]],
        tenant_id: str = 'default'
    ) -> int:
        """
        æ‰¹é‡å‘å¸ƒäº‹ä»¶
        
        å‚æ•°:
            events: äº‹ä»¶åˆ—è¡¨ï¼Œæ¯ä¸ªäº‹ä»¶åŒ…å« kind, user_id, payload ç­‰å­—æ®µ
            tenant_id: ç§Ÿæˆ·ID
        
        è¿”å›:
            æˆåŠŸå‘å¸ƒçš„äº‹ä»¶æ•°é‡
        
        ç¤ºä¾‹:
            >>> events = [
            ...     {'kind': 'miner.added', 'user_id': 'user1', 'payload': {...}},
            ...     {'kind': 'miner.updated', 'user_id': 'user1', 'payload': {...}}
            ... ]
            >>> count = outbox.publish_batch(events)
        """
        count = 0
        
        try:
            for event in events:
                event_id = self.publish(
                    kind=event['kind'],
                    user_id=event['user_id'],
                    payload=event['payload'],
                    entity_id=event.get('entity_id'),
                    tenant_id=event.get('tenant_id', tenant_id),
                    idempotency_key=event.get('idempotency_key')
                )
                
                if event_id:
                    count += 1
            
            logger.info(f"ğŸ“¤ Batch published: {count}/{len(events)} events")
            return count
        
        except Exception as e:
            logger.error(f"âŒ Batch publish failed: {e}")
            raise
    
    def get_pending_events(self, limit: int = 100) -> list:
        """
        è·å–å¾…å¤„ç†çš„äº‹ä»¶ï¼ˆç”¨äºå¤‡ç”¨è½®è¯¢æœºåˆ¶ï¼‰
        
        å‚æ•°:
            limit: è¿”å›æ•°é‡é™åˆ¶
        
        è¿”å›:
            å¾…å¤„ç†äº‹ä»¶åˆ—è¡¨
        """
        try:
            sql = text("""
                SELECT id, kind, user_id, tenant_id, entity_id, 
                       payload, created_at
                FROM event_outbox
                WHERE processed = false
                ORDER BY created_at ASC
                LIMIT :limit
            """)
            
            result = self.db.session.execute(sql, {'limit': limit})
            events = []
            
            for row in result:
                events.append({
                    'id': row.id,
                    'kind': row.kind,
                    'user_id': row.user_id,
                    'tenant_id': row.tenant_id,
                    'entity_id': row.entity_id,
                    'payload': row.payload,
                    'created_at': row.created_at
                })
            
            return events
        
        except SQLAlchemyError as e:
            logger.error(f"âŒ Failed to get pending events: {e}")
            return []
    
    def mark_as_processed(self, event_id: str) -> bool:
        """
        æ ‡è®°äº‹ä»¶ä¸ºå·²å¤„ç†ï¼ˆç”¨äºå¤‡ç”¨è½®è¯¢æœºåˆ¶ï¼‰
        
        å‚æ•°:
            event_id: äº‹ä»¶ID
        
        è¿”å›:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            sql = text("""
                UPDATE event_outbox
                SET processed = true, processed_at = :processed_at
                WHERE id = :event_id
            """)
            
            self.db.session.execute(sql, {
                'event_id': event_id,
                'processed_at': datetime.utcnow()
            })
            self.db.session.commit()
            
            logger.debug(f"âœ… Event marked as processed: {event_id}")
            return True
        
        except SQLAlchemyError as e:
            logger.error(f"âŒ Failed to mark event as processed: {e}")
            self.db.session.rollback()
            return False
    
    def cleanup_old_events(self, days: int = 7) -> int:
        """
        æ¸…ç†å·²å¤„ç†çš„æ—§äº‹ä»¶
        
        å‚æ•°:
            days: ä¿ç•™å¤©æ•°
        
        è¿”å›:
            åˆ é™¤çš„äº‹ä»¶æ•°é‡
        """
        try:
            sql = text("""
                DELETE FROM event_outbox
                WHERE processed = true
                AND processed_at < NOW() - INTERVAL ':days days'
            """)
            
            result = self.db.session.execute(sql, {'days': days})
            count = result.rowcount
            self.db.session.commit()
            
            logger.info(f"ğŸ§¹ Cleaned up {count} old outbox events (>{days} days)")
            return count
        
        except SQLAlchemyError as e:
            logger.error(f"âŒ Cleanup failed: {e}")
            self.db.session.rollback()
            return 0
    
    def get_stats(self) -> Dict[str, Any]:
        """
        è·å–Outboxç»Ÿè®¡ä¿¡æ¯
        
        è¿”å›:
            ç»Ÿè®¡å­—å…¸
        """
        try:
            sql = text("""
                SELECT 
                    COUNT(*) FILTER (WHERE processed = false) as pending,
                    COUNT(*) FILTER (WHERE processed = true) as processed,
                    COUNT(*) as total,
                    MIN(created_at) FILTER (WHERE processed = false) as oldest_pending
                FROM event_outbox
            """)
            
            result = self.db.session.execute(sql).first()
            
            return {
                'pending': result.pending or 0,
                'processed': result.processed or 0,
                'total': result.total or 0,
                'oldest_pending': result.oldest_pending.isoformat() if result.oldest_pending else None
            }
        
        except SQLAlchemyError as e:
            logger.error(f"âŒ Failed to get stats: {e}")
            return {'error': str(e)}

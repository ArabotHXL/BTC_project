"""
æ‰©å±•å†å²æ•°æ®åˆ°2023å¹´
ç”Ÿæˆ2023å¹´å®Œæ•´å¹´åº¦çš„BTCå†å²æ•°æ®
"""

import os
import psycopg2
from datetime import datetime, timedelta
import logging
import random

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ExtendTo2023:
    
    def __init__(self):
        self.db_url = os.environ.get('DATABASE_URL')
        
    def get_connection(self):
        return psycopg2.connect(self.db_url)
    
    def generate_2023_data(self):
        """ç”Ÿæˆ2023å¹´å…¨å¹´çš„BTCå†å²æ•°æ®"""
        logger.info("å¼€å§‹ç”Ÿæˆ2023å¹´å†å²æ•°æ®...")
        
        # 2023å¹´å…³é”®ä»·æ ¼ç‚¹ï¼ˆåŸºäºçœŸå®å†å²ï¼‰
        key_prices = {
            datetime(2023, 1, 1): 16625,    # 2023å¹´å¼€å¹´
            datetime(2023, 3, 15): 24500,   # é“¶è¡Œå±æœºååå¼¹
            datetime(2023, 6, 15): 26000,   # å¹´ä¸­é«˜ç‚¹
            datetime(2023, 10, 30): 35000,  # å¹´æœ«ç‰›å¸‚å¼€å§‹
            datetime(2023, 12, 31): 42500   # 2023å¹´æ”¶ç›˜
        }
        
        data_points = []
        start_date = datetime(2023, 1, 1)
        end_date = datetime(2023, 12, 31)
        current_date = start_date
        
        while current_date <= end_date:
            # æ’å€¼è®¡ç®—å½“æ—¥ä»·æ ¼
            price = self.interpolate_price(current_date, key_prices)
            
            # ç®—åŠ›æ¨¡æ‹Ÿï¼ˆ2023å¹´ä»300EH/så¢é•¿åˆ°500EH/sï¼‰
            days_in_year = (current_date - start_date).days
            year_progress = days_in_year / 365
            hashrate = 300 + (200 * year_progress)  # 300 -> 500 EH/s
            
            # æ·»åŠ éšæœºæ³¢åŠ¨
            random.seed(int(current_date.timestamp()))
            price *= random.uniform(0.95, 1.05)
            hashrate *= random.uniform(0.9, 1.1)
            
            # è®¡ç®—å…¶ä»–å‚æ•°
            difficulty = hashrate * 1.3e14
            volume = random.uniform(8e9, 25e9)  # 8-25Bæ—¥æˆäº¤é‡
            market_cap = price * 19500000  # 2023å¹´æµé€šé‡çº¦1950ä¸‡
            
            data_points.append({
                'timestamp': current_date,
                'price': round(price, 2),
                'hashrate': round(hashrate, 2),
                'difficulty': round(difficulty, 0),
                'volume': round(volume, 0),
                'market_cap': round(market_cap, 0)
            })
            
            current_date += timedelta(days=1)
        
        logger.info(f"ç”Ÿæˆäº†{len(data_points)}ä¸ª2023å¹´æ•°æ®ç‚¹")
        return data_points
    
    def interpolate_price(self, target_date, key_prices):
        """æ’å€¼è®¡ç®—æŒ‡å®šæ—¥æœŸçš„ä»·æ ¼"""
        # æ‰¾åˆ°æœ€è¿‘çš„ä¸¤ä¸ªå…³é”®ç‚¹
        before_date, before_price = None, None
        after_date, after_price = None, None
        
        sorted_dates = sorted(key_prices.keys())
        
        for date in sorted_dates:
            if date <= target_date:
                before_date, before_price = date, key_prices[date]
            else:
                after_date, after_price = date, key_prices[date]
                break
        
        if not before_date:
            return list(key_prices.values())[0]
        if not after_date:
            return before_price
        
        # çº¿æ€§æ’å€¼
        total_days = (after_date - before_date).days
        elapsed_days = (target_date - before_date).days
        
        if total_days == 0:
            return before_price
            
        progress = elapsed_days / total_days
        interpolated_price = before_price + (after_price - before_price) * progress
        
        return interpolated_price
    
    def insert_2023_data(self, data_points):
        """æ’å…¥2023å¹´æ•°æ®"""
        conn = self.get_connection()
        cursor = conn.cursor()
        
        inserted = 0
        
        for point in data_points:
            try:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                cursor.execute("""
                    SELECT COUNT(*) FROM market_analytics 
                    WHERE DATE(recorded_at) = %s
                """, (point['timestamp'].date(),))
                
                if cursor.fetchone()[0] > 0:
                    continue
                
                cursor.execute("""
                    INSERT INTO market_analytics (
                        recorded_at, btc_price, btc_market_cap, btc_volume_24h,
                        network_hashrate, network_difficulty, 
                        fear_greed_index, source_apis
                    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    point['timestamp'],
                    point['price'],
                    point['market_cap'],
                    point['volume'],
                    point['hashrate'],
                    point['difficulty'],
                    50,
                    '2023_historical_model'
                ))
                
                inserted += 1
                
                if inserted % 30 == 0:
                    conn.commit()
                    logger.info(f"å·²æ’å…¥{inserted}æ¡2023å¹´æ•°æ®...")
                    
            except Exception as e:
                logger.error(f"æ’å…¥å¤±è´¥: {e}")
                continue
        
        conn.commit()
        cursor.close()
        conn.close()
        
        logger.info(f"2023å¹´æ•°æ®æ’å…¥å®Œæˆï¼š{inserted}æ¡")
        return inserted

def main():
    extender = ExtendTo2023()
    
    logger.info("=== æ‰©å±•å†å²æ•°æ®åˆ°2023å¹´ ===")
    
    # ç”Ÿæˆå¹¶æ’å…¥2023å¹´æ•°æ®
    data_2023 = extender.generate_2023_data()
    inserted_count = extender.insert_2023_data(data_2023)
    
    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    conn = extender.get_connection()
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT 
            COUNT(*) as total_records,
            MIN(DATE(recorded_at)) as earliest_date,
            MAX(DATE(recorded_at)) as latest_date,
            COUNT(DISTINCT DATE(recorded_at)) as unique_days
        FROM market_analytics
    """)
    
    total, earliest, latest, unique_days = cursor.fetchone()
    
    # æŒ‰å¹´ä»½ç»Ÿè®¡
    cursor.execute("""
        SELECT 
            EXTRACT(YEAR FROM recorded_at) as year,
            COUNT(*) as records,
            COUNT(DISTINCT DATE(recorded_at)) as days
        FROM market_analytics
        GROUP BY EXTRACT(YEAR FROM recorded_at)
        ORDER BY year
    """)
    
    yearly_stats = cursor.fetchall()
    
    cursor.close()
    conn.close()
    
    print(f"\nâœ… å†å²æ•°æ®æ‰©å±•åˆ°2023å¹´å®Œæˆï¼")
    print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡ï¼š")
    print(f"   æ€»è®°å½•æ•°: {total:,}")
    print(f"   æ—¶é—´è·¨åº¦: {earliest} åˆ° {latest}")
    print(f"   è¦†ç›–å¤©æ•°: {unique_days}")
    print(f"   æœ¬æ¬¡æ–°å¢: {inserted_count}æ¡")
    
    print(f"\nğŸ“… å¹´åº¦åˆ†å¸ƒï¼š")
    for year, records, days in yearly_stats:
        print(f"   {int(year)}: {records:,}æ¡è®°å½•ï¼Œè¦†ç›–{days}å¤©")

if __name__ == "__main__":
    main()
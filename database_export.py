#!/usr/bin/env python3
"""
æ•°æ®åº“å®Œæ•´å¯¼å‡ºå·¥å…·
å¯¼å‡ºæ‰€æœ‰è¡¨çš„æ•°æ®ä¸ºå¤šç§æ ¼å¼
"""

import os
import psycopg2
import pandas as pd
from datetime import datetime
import json
import csv

def get_database_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    database_url = os.environ.get('DATABASE_URL')
    if not database_url:
        raise ValueError("DATABASE_URL environment variable not found")
    return psycopg2.connect(database_url)

def get_all_tables(conn):
    """è·å–æ‰€æœ‰è¡¨å"""
    cursor = conn.cursor()
    cursor.execute("""
        SELECT table_name 
        FROM information_schema.tables 
        WHERE table_schema = 'public' 
        ORDER BY table_name;
    """)
    tables = [row[0] for row in cursor.fetchall()]
    cursor.close()
    return tables

def export_table_to_csv(conn, table_name, output_dir):
    """å¯¼å‡ºè¡¨ä¸ºCSVæ ¼å¼"""
    try:
        df = pd.read_sql_query(f"SELECT * FROM {table_name}", conn)
        csv_file = os.path.join(output_dir, f"{table_name}.csv")
        df.to_csv(csv_file, index=False, encoding='utf-8')
        return len(df), csv_file
    except Exception as e:
        print(f"Error exporting {table_name} to CSV: {e}")
        return 0, None

def export_table_to_json(conn, table_name, output_dir):
    """å¯¼å‡ºè¡¨ä¸ºJSONæ ¼å¼"""
    try:
        df = pd.read_sql_query(f"SELECT * FROM {table_name}", conn)
        # å¤„ç†æ—¥æœŸæ—¶é—´å­—æ®µ
        df = df.where(pd.notnull(df), None)
        for col in df.columns:
            if df[col].dtype == 'datetime64[ns]':
                df[col] = df[col].dt.strftime('%Y-%m-%d %H:%M:%S')
        
        json_file = os.path.join(output_dir, f"{table_name}.json")
        df.to_json(json_file, orient='records', indent=2, force_ascii=False)
        return len(df), json_file
    except Exception as e:
        print(f"Error exporting {table_name} to JSON: {e}")
        return 0, None

def export_all_data():
    """å¯¼å‡ºæ‰€æœ‰æ•°æ®"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"database_export_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)
    
    export_summary = {
        "export_timestamp": datetime.now().isoformat(),
        "tables_exported": [],
        "total_records": 0,
        "files_created": []
    }
    
    try:
        conn = get_database_connection()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        tables = get_all_tables(conn)
        print(f"ğŸ“Š å‘ç° {len(tables)} ä¸ªè¡¨:")
        for table in tables:
            print(f"  - {table}")
        
        print(f"\nğŸš€ å¼€å§‹å¯¼å‡ºæ•°æ®åˆ°ç›®å½•: {output_dir}")
        
        for table_name in tables:
            print(f"\nğŸ“‹ å¯¼å‡ºè¡¨: {table_name}")
            
            # å¯¼å‡ºä¸ºCSV
            csv_count, csv_file = export_table_to_csv(conn, table_name, output_dir)
            if csv_file:
                print(f"  âœ… CSV: {csv_count} æ¡è®°å½• -> {csv_file}")
                export_summary["files_created"].append(csv_file)
            
            # å¯¼å‡ºä¸ºJSON
            json_count, json_file = export_table_to_json(conn, table_name, output_dir)
            if json_file:
                print(f"  âœ… JSON: {json_count} æ¡è®°å½• -> {json_file}")
                export_summary["files_created"].append(json_file)
            
            table_info = {
                "table_name": table_name,
                "record_count": csv_count if csv_count else json_count,
                "csv_file": csv_file,
                "json_file": json_file
            }
            export_summary["tables_exported"].append(table_info)
            export_summary["total_records"] += table_info["record_count"]
        
        # ä¿å­˜å¯¼å‡ºæ‘˜è¦
        summary_file = os.path.join(output_dir, "export_summary.json")
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(export_summary, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ‰ å¯¼å‡ºå®Œæˆ!")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“Š æ€»è®¡ {len(tables)} ä¸ªè¡¨, {export_summary['total_records']} æ¡è®°å½•")
        print(f"ğŸ“„ å¯¼å‡ºæ‘˜è¦: {summary_file}")
        
        conn.close()
        
    except Exception as e:
        print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
        return None
    
    return output_dir

if __name__ == "__main__":
    export_dir = export_all_data()
    if export_dir:
        print(f"\nâœ¨ æ•°æ®åº“å®Œæ•´å¯¼å‡ºå®Œæˆ: {export_dir}")